\begin{abstract}
  GEneral Matrix Multiply (GEMM) is the most fundamental
  computational kernel routine in the BLAS library.
  To achieve high performance, in-memory data must be
  prefetched into fast on-chip caches before they are used.
  Two techniques, software prefetching and data packing,
  are utilized to effectively exploit the capability of on-chip caches.
  These techniques are sufficient for lastly-recent-used (LRU) caches,
  which are often used in high-performance
  processors deployed in high-end servers and supercomputers.
  But in recent years the market has become increasingly more diverse
  in processor design, resulting in high-performance processors
  equipped with shared caches with non-LRU replacement policies.
  This poses a challenge to GEMM development in a multi-threaded context.
  As several threads try to load data into the shared cache simultaneously,
  inter-thread cache conflicts will increase significantly.
  We present a Shared Cache Partitioning (SCP) method to
  eliminate inter-thread cache conflicts in GEMM routines,
  by partitioning the shared cache into physically disjoint
  sets and assign different sets to different threads.
  We implement SCP in the OpenBLAS library and
  evaluate the performance on Phytium 2000+,
  a 64-core AArch64 processor with private LRU L1 caches
  and shared (by every 4 cores) psudo-random L2 caches.
  The results show that conflict misses on both L1 and L2
  caches are effectively reduced, resulting in an improvement
  of the GEMM performance by $2.75\%$--$6.91\%$.
\end{abstract}
